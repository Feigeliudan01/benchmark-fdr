# Roadmap

Thanks to everyone who expressed interest in working on this!  

The purpose of this benchmarking project is to evaluate and compare a set of [methods](notes/1_methods.md) recently developed for using covariates to improve false discovery rate (FDR) estimation. Hopefully, at the end of this, we'll have a set of recommendations and/or a summary of relative strengths and weaknesses for each approach.  

This "Roadmap" is a rough outline of how we can complete this project **as a group**.  
**If you have any suggestions/thoughts on the Roadmap**, add them to issue [#1](https://github.com/pkimes/benchmark-fdr/issues/1)!

## Milestone 1: decide initial benchmarking setup
*Tracking in issue(s) [#2](https://github.com/pkimes/benchmark-fdr/issues/2), [#4](https://github.com/pkimes/benchmark-fdr/issues/4).* 

- [x] survey previous simulations and data sets [(**#2**)](https://github.com/pkimes/benchmark-fdr/issues/2) 
- [ ] agree on initial set of simulations and data sets [(**#4**)](https://github.com/pkimes/benchmark-fdr/issues/4)

## Milestone 2: perform benchmarking analyses
*Tracking in issue(s) (not yet assigned).*

- [ ] run simulations and real data analyses (**sign-up!**)
- [ ] review results as a group
- [ ] determine follow-up analyses and update Roadmap

## Milestone 3: write-up and wrap-up
*Tracking in issue(s) (not yet assigned).*

- [ ] agree on format (Rmd?) and target venue of write-up
- [ ] complete first draft and compile analyses (**sign-up!**)
- [ ] get full group approval on draft
- [ ] submit! :tada: 
