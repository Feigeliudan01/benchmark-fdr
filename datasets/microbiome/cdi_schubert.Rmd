---
title: "CDI Schubert"
author: "Claire Duvallet"
date: "9/21/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Summary

This script will download one processed OTU table from Zenodo, calculate p-values for
OTU abundances in cases vs. controls, and also calculate some covariates like ubiquity,
abundance, and average reads.

## Data

Note: later, we'll be using the following datasets:

- cdi_schubert: 154 healthy, 93 CDI, 89 nonCDI (we can either do CDI vs. healthy or any diarrhea vs. healthy)
- ob_goodrich: 428 healthy, 185 obese
- crc_baxter: 172 healthy, 120 CRC
- ibd_gevers: 16 nonIBD, 146 Crohn's
      - note: the two largest IBD datasets are very uneven (ibd_morgan has 18 healthy, 108 IBD). We could 
  aso use ibd_papa, which has 24 nonIBD and 66 IBD

### CDI Schubert

Let's start with the cdi_schubert dataset first...

```{r}
library(dplyr)
library(ggplot2)
library(cowplot)

wd <- "/Users/claire/github/benchmark-fdr/datasets/microbiome/"
setwd(wd)
source("../../simulation_studies/R/simulation-helpers.R")
source("../R/evaluation-helpers.R")
resdir <- "/Users/claire/github/benchmark-fdr/datasets/microbiome/"
```

```{bash, schubert-download, eval=FALSE}
curl -O "https://zenodo.org/record/840333/files/cdi_schubert_results.tar.gz"
tar -xzvf cdi_schubert_results.tar.gz
```

```{r, data_functions, echo = FALSE, results='hide'}
# Define functions to read and clean up data

remove_shallow_smpls <- function(df, n_reads) {
  # Removes samples with fewer than n_reads from dataframe df.
  # df has OTUs in rows and samples in columns
  return(df[, colSums(df) > n_reads])
  }

remove_shallow_otus <- function(df, n_reads){
  return(df[rowSums(df) > n_reads, ])
  }

read_and_clean_data <- function(otu_path, meta_path, labels, col_label,
                                sample_reads = 1000, otu_reads = 10) {
  # Reads the OTU table and metadata from otu_path and meta_path,
  # keeps samples which have both metadata and 16S data and whose
  # DiseaseState is in the list labels. Removes samples with fewer
  # than sample_reads reads, and and OTUs with fewer than otu_reads
  # reads. Metadata should have sample IDs in first column and a column
  # labeled DiseaseState
  
  # load OTU table and metadata
  otu <- read.table(otu_path)
  meta <- read.csv(meta_path, sep='\t')

  # Keep only samples with the right DiseaseState metadata
  meta <- meta %>% filter(DiseaseState %in% labels)

  # Keep only samples with both metadata and 16S data
  keep_samples <- intersect(colnames(otu), meta[, 1])
  otu <- otu[, keep_samples]
  meta <- meta %>% filter(get(col_label) %in% keep_samples)
  # Other ways to do this:
  #meta[meta[, col_label] %in% keep_samples, ]
  #meta[col_label]
  #`[[`(meta, col_label)

  # Remove OTUs and samples without enough reads
  otu <- remove_shallow_smpls(otu, sample_reads)
  otu <- remove_shallow_otus(otu, otu_reads)

  # Update metadata with new samples
  meta <- meta %>% filter(get(col_label) %in% colnames(otu))

  return(list(otu, meta))
}
```

```{r, covariate_calcs, echo = FALSE, results='hide'}
calculate_covariates <- function(otu, abun_otu){
  # Calculates covariates for the OTU table.
  # OTU table should have OTUs in rows and samples in columns.
  # This function calculates (per OTU): mean read depth, 
  # ubiquity, mean relative abundance in non-zero samples.
  # It returns a dataframe with each of these as columns, in addition
  # to "otu".
  # zeroabun is the value in abun_otu corresponding to zero abundance.
  
  # Mean read depth
  reads <- rowMeans(otu)
  
  # Ubiquity
  ubi <- rowSums(otu > 0) / length(rownames(otu))
  
  # Mean relative abundance (only considering people who have the OTU present)
  mean_abun <- rowSums(abun_otu) / rowSums(abun_otu > 0)

  covdf <- data.frame(otu = rownames(otu), mean_abun = mean_abun,
                      ubiquity = ubi, mean_reads = reads)
  return(covdf)
}
```

```{r, calculate_pvals, echo = FALSE}
calculate_pvals <- function(abun_otu, ctrl_idx, case_idx){
  # Does wilcoxon rank sum test for all OTUs between cases and
  # controls. abun_otu is a dataframe with OTUs in rows and 
  # samples in columns. ctrl_idx and case_idx are boolean
  # vectors indicating the columns correspnding to control
  # and case samples, respectively.
  # This function also calculate the effect size 
  # (difference of mean abundances) and standard error
  
  pvals <- c()
  ses <- c()
  effs <- c()
  
  casedf <- abun_otu[, case_idx]
  ctrldf <- abun_otu[, ctrl_idx]
  for (o in rownames(abun_otu)) {
    p <- wilcox.test(casedf[o, ], 
                     ctrldf[o, ])$p.value
    pvals <- c(pvals, p)
    
    # standard error
    ses <- c(ses, sd(abun_otu[o,])/sqrt(length(abun_otu[o,])))
    
    # effect (difference of means)
    effs <- c(effs, mean(abun_otu[o, ctrl_idx]) - mean(abun_otu[o, case_idx]))
  
  }
  res <- data.frame(otu = rownames(abun_otu), pval = pvals, SE = ses, effect_size = effs)
  return(res)
}

```

```{r, def_strat_hist}
strat_hist <- function(dat, pval, covariate, binwidth=0.025, maxy=3){
  gg_all <- ggplot(data=schubertdat, aes(x=get(pcol))) + 
    geom_histogram(binwidth = binwidth, boundary = 0, 
                   colour="grey", fill="lightgrey") +
    aes(y=..density..)+
    theme_classic() +
    theme(axis.title = element_text(face="bold"),
          plot.title = element_text(face="bold")) +
    scale_x_continuous(expand = c(0.02, 0)) + 
    scale_y_continuous(expand = c(0.02, 0), limits=c(0,maxy)) + 
    xlab("p-value") +
    ylab("Density") +
    ggtitle("All OTUs")
  
  dat.strat <- schubertdat %>% 
      filter(-rank(get(covcol), ties="first") > quantile(-rank(get(covcol), ties="first"), 2/3))
  gg_top <- ggplot(data=dat.strat, aes(x=get(pcol))) + 
    geom_histogram(binwidth = binwidth, boundary = 0, 
                   colour="grey", fill="lightgrey") +
    aes(y=..density..) +
    theme_classic() +
    theme(axis.title = element_text(face="bold"),
          plot.title = element_text(face="bold")) +
    scale_x_continuous(expand = c(0.02, 0)) + 
    scale_y_continuous(expand = c(0.02, 0), limits=c(0,maxy)) + 
    xlab("p-value") +
    ylab("Density") +
    ggtitle(paste0("Top third by ", covcol))
  
  dat.strat <- dat %>% 
    filter(-rank(get(covcol), ties="first") <= quantile(-rank(get(covcol), ties="first"), 2/3) &
           -rank(get(covcol), ties="first") > quantile(-rank(get(covcol), ties="first"), 1/3) )
  gg_mid <- ggplot(data=dat.strat, aes(x=get(pcol))) + 
    geom_histogram(binwidth = binwidth, boundary = 0, 
                   colour="grey", fill="lightgrey") +
    aes(y=..density..)+
    theme_classic() +
    theme(axis.title = element_text(face="bold"),
          plot.title = element_text(face="bold")) +
    scale_x_continuous(expand = c(0.02, 0)) + 
    scale_y_continuous(expand = c(0.02, 0), limits=c(0,maxy)) + 
    xlab("p-value") +
    ylab("Density") +
    ggtitle(paste0("Middle third by ", covcol))
  
  dat.strat <- dat %>% 
    filter(-rank(get(covcol), ties="first") <= quantile(-rank(get(covcol), ties="first"), 1/3))
  gg_bot <- ggplot(data=dat.strat, aes(x=get(pcol))) + 
    geom_histogram(binwidth = binwidth, boundary = 0, 
                   colour="grey", fill="lightgrey") +
    aes(y=..density..) +
    theme_classic() +
    theme(axis.title = element_text(face="bold"),
          plot.title = element_text(face="bold")) +
    scale_x_continuous(expand = c(0.02, 0)) + 
    scale_y_continuous(expand = c(0.02, 0), limits=c(0,maxy)) + 
    xlab("p-value") +
    ylab("Density") +
    ggtitle(paste0("Lower third by ", covcol))
  
  gg_stratified <- plot_grid(gg_all, gg_top, gg_mid, gg_bot,
                             nrow=1,
                             labels=c("(a)", "(b)", "(c)","(d)"),
                             hjust = 0.1)
  return(gg_stratified)
}
```

```{r}
# Read and clean cdi_schubert
otu_path = paste0(wd, "cdi_schubert_results/RDP/cdi_schubert.otu_table.100.denovo.rdp_assigned")
meta_path = paste0(wd, "cdi_schubert_results/cdi_schubert.metadata.txt")
labels = c("H", "nonCDI", "CDI")

dat <- read_and_clean_data(otu_path, meta_path, labels, 'sample_id')
otu <- dat[[1]]
meta <- dat[[2]]

abun_otu <- t(t(otu) / rowSums(t(otu)))
minabun <- min(abun_otu[abun_otu > 0])
zeroabun = 1e-6
abun_otu <- abun_otu + zeroabun
```

```{r, schubert-pvals}
case_idx <- meta$DiseaseState %in% c("CDI", "nonCDI")
ctrl_idx <- meta$DiseaseState %in% c("H")

# Calculate some basic covariates for each OTU
schubertdat <- calculate_covariates(otu, abun_otu)
# Get the pvalues, effects, and SEs
schu_pvals <- calculate_pvals(abun_otu, ctrl_idx, case_idx)
schubertdat <- merge(schubertdat, schu_pvals, by="otu")
schubertdat <- schubertdat %>% 
                 mutate(logpval = log10(pval)) %>%
                 mutate(neglogpval = -log10(pval)) %>%
                 mutate(logubiquity = log10(ubiquity)) %>%
                 mutate(logmean_reads = log10(mean_reads))
head(schubertdat)
```

```{r}
pcol <- "pval"
covcol <- "logubiquity"
binwidth <- 0.025
maxy <- 3
strat_hist(schubertdat, pcol, covcol)
```
```{r}
g <- ggplot(schubertdat, aes(x = get(covcol), y = pval)) + geom_point()
g 
```

```{r}
covcol <- "logmean_reads"
strat_hist(schubertdat, pcol, covcol)
```

```{r}
g <- ggplot(schubertdat, aes(x = get(covcol), y = pval)) + geom_point()
g 
```

```{r, run_cdi_schubert}
# Set up ubiquity as the first covariate to test.
# Ranges from 0.001 to 0.4
schubertdat <- schubertdat %>% 
              mutate(zscore = effect_size/SE) %>%
              mutate(ind_covariate = log10(ubiquity) )

# Run all the tests and plot
cutoffs <- c(0.01, 0.025, 0.05, 0.10, 0.20)
resfile <- paste0(resdir, "cdi_schubert_results_",
                  nrow(schubertdat), ".RData")
t1 <- proc.time()
schu_results <- run_benchmarks(dat=schubertdat, alphas=cutoffs)
save(schu_results, file=resfile)
message(paste0("Took ", round((proc.time()-t1)[3],1),
               " seconds for ", nrow(schubertdat), " OTUs"))

# plot % rejects vs FDR cutoff
schu_results <- schu_results %>% mutate(perc_reject = n_rejects / length(rownames(abun_otu)))
p <- ggplot(schu_results, aes(alpha, perc_reject, color=method)) +
  geom_point() +
  geom_line() +
  xlab("FDR cutoff") + ylab("Fraction of hypotheses rejected") +
  ggtitle("CDI Schubert with log10(Ubiquity) Covariate") +
  theme_classic()
print(p)
```

```{bash, goodrich-download, eval=FALSE}
curl -O "https://zenodo.org/record/840333/files/ob_goodrich_results.tar.gz"
tar -xzvf ob_goodrich_results.tar.gz
```

```{r, read-ob-goodrich}
# Read and clean ob_goodrich
otu_path = paste0(wd, "ob_goodrich_results/RDP/ob_goodrich.otu_table.100.denovo.rdp_assigned")
meta_path = paste0(wd, "ob_goodrich_results/ob_goodrich.metadata.txt")
labels = c("H", "OB")

dat <- read_and_clean_data(otu_path, meta_path, labels, "X")
otu <- dat[[1]]
meta <- dat[[2]]

abun_otu <- t(t(otu) / rowSums(t(otu)))
minabun <- min(abun_otu[abun_otu > 0])
zeroabun = 1e-6
abun_otu <- abun_otu + zeroabun
```

```{r, goodrich-pvals}
case_idx <- meta$DiseaseState %in% c("OB")
ctrl_idx <- meta$DiseaseState %in% c("H")

# Calculate some basic covariates for each OTU
goodrichdat <- calculate_covariates(otu, abun_otu)
# Get the pvalues, effects, and SEs
goodrich_pvals <- calculate_pvals(abun_otu, ctrl_idx, case_idx)
goodrichdat <- merge(goodrichdat, goodrich_pvals, by="otu")
```

```{r}
goodrichdat <- goodrichdat %>% 
                 mutate(logpval = log10(pval)) %>%
                 mutate(neglogpval = -log10(pval)) %>%
                 mutate(logubiquity = log10(ubiquity)) %>%
                 mutate(logmean_reads = log10(mean_reads))
head(goodrichdat)
```

```{r}
covcol <- "logubiquity"
strat_hist(goodrichdat, pcol, covcol)
```

```{r, explore-goodrich-covariates}
var <- "logubiquity"
g <- ggplot(goodrichdat, aes(x = get(var), y = pval)) + geom_point()
g
```

```{r}
covcol <- "logmean_reads"
strat_hist(goodrichdat, pcol, covcol)
```

```{r}
g <- ggplot(goodrichdat, aes(x = get(covcol), y = pval)) + geom_point()
g
```

```{r, test-fdrs-ubiquity}
# Set up ubiquity as the first covariate to test.
# Ranges from 0.001 to 0.4
goodrichdat <- goodrichdat %>% 
              mutate(zscore = effect_size/SE) %>%
              mutate(ind_covariate = log10(ubiquity) )

# Run all the tests and plot
cutoffs <- c(0.01, 0.025, 0.05, 0.10, 0.20)
resfile <- paste0(resdir, "ob_goodrich_results_",
                  nrow(goodrichdat), ".RData")
t1 <- proc.time()
goodrich_results <- run_benchmarks(dat=goodrichdat, alphas=cutoffs)
save(goodrich_results, file=resfile)
message(paste0("Took ", round((proc.time()-t1)[3],1),
               " seconds for ", nrow(goodrichdat), " OTUs"))

# plot % rejects vs FDR cutoff
goodrich_results <- goodrich_results %>% 
  mutate(perc_reject = n_rejects / length(rownames(abun_otu)))

p <- ggplot(goodrich_results, aes(alpha, perc_reject, color=method)) +
  geom_point() +
  geom_line() +
  xlab("FDR cutoff") + ylab("Fraction of hypotheses rejected") +
  ggtitle("OB Goodrich with log10(Ubiquity) Covariate") +
  theme_classic()
print(p)
```