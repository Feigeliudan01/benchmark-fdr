---
title: "ChIP-seq datasets for FDR benchmarking"
author: "Mingxiang Teng"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "~/workspace/cowork/fdr/")
```

### Summary

For FDR benchmark using ChIP-seq datasets, we may focus on peak calling and
differential peaks. Peak calling has been the most common procedure to analyze 
ChIP-seq since this technique was invented, though people started to look
into differential peaks in some complex experiment designs. In peak calling,
callers always report effect size (they call "enrichment signal") 
and p-value, but standard error. It is complicate to hack the original
code for re-generating standard errors. In differential peaks, classical
pipelines firstly call peaks, and recruit existing algorithms (*i.e.* edgeR/DESeq2)
to test the covariant of interest later, in a way that the effect size, p-value and 
standard error can be generated at the same time. 

Here, we focus on test the differential peaks. It is noted that by using DESeq2
to test the differential peaks, we have introduced similarity into testing results to that
we used for RNA-seq differential analysis. Nevertheless, benchmarking on ChIP-seq still provides
insights with a unique data structure which has been widely utilized in modern genomics.


### Testing differential ChIP-seq signals between two cell lines (K562 *vs.* Gm12878)
These two cell lines hold the largest sequencing datasets on ENCODE project. 
We chose histone H3K4Me3 ChIP-seq data for our analysis here. 

#### Data Download

We download the bam files directly from UCSC ENCODE protal.

```{bash, encode-download, eval=FALSE}
wget -N -P data http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeBroadHistone/wgEncodeBroadHistoneGm12878H3k4me3StdAlnRep1.bam
wget -N -P data http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeBroadHistone/wgEncodeBroadHistoneGm12878H3k4me3StdAlnRep1.bam.bai
wget -N -P data http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeBroadHistone/wgEncodeBroadHistoneGm12878H3k04me3StdAlnRep2V2.bam
wget -N -P data http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeBroadHistone/wgEncodeBroadHistoneGm12878H3k04me3StdAlnRep2V2.bam.bai
wget -N -P data http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeBroadHistone/wgEncodeBroadHistoneK562H3k4me3StdAlnRep1.bam
wget -N -P data http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeBroadHistone/wgEncodeBroadHistoneK562H3k4me3StdAlnRep1.bam.bai
wget -N -P data http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeBroadHistone/wgEncodeBroadHistoneK562H3k4me3StdAlnRep2.bam
wget -N -P data http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeBroadHistone/wgEncodeBroadHistoneK562H3k4me3StdAlnRep2.bam.bai
wget -N -P data http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeUwHistone/wgEncodeUwHistoneGm12878H3k4me3StdAlnRep1.bam
wget -N -P data http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeUwHistone/wgEncodeUwHistoneGm12878H3k4me3StdAlnRep1.bam.bai
wget -N -P data http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeUwHistone/wgEncodeUwHistoneGm12878H3k4me3StdAlnRep2.bam
wget -N -P data http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeUwHistone/wgEncodeUwHistoneGm12878H3k4me3StdAlnRep2.bam.bai
wget -N -P data http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeUwHistone/wgEncodeUwHistoneK562H3k4me3StdAlnRep1.bam
wget -N -P data http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeUwHistone/wgEncodeUwHistoneK562H3k4me3StdAlnRep1.bam.bai
wget -N -P data http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeUwHistone/wgEncodeUwHistoneK562H3k4me3StdAlnRep2.bam
wget -N -P data http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeUwHistone/wgEncodeUwHistoneK562H3k4me3StdAlnRep2.bam.bai
```

#### Workspace Setup

```{r, wkspace-setup, results='hide', message=FALSE, warning=FALSE}
datdir <- "data"
resdir <- "results"
# wrangling & plotting tools
library(data.table)
library(readxl)
library(readr)
library(dplyr)
library(ggplot2)
library(magrittr)
library(R.utils)
library(cowplot)
# benchmark methods
library(IHW)
library(ashr)
library(qvalue)
library(swfdr)
library(fdrtool)
library(FDRreg)
# comparison tools/functions
library(SummarizedBenchmark)
library(R.utils)
sourceDirectory("benchmark-fdr/datasets/R/")
# set up parallel backend
library(BiocParallel)
cores <- as.numeric(Sys.getenv("SLURM_NTASKS"))
multicoreParam <- MulticoreParam(workers = cores)
library(GenomicRanges)
library(TxDb.Hsapiens.UCSC.hg19.knownGene)
prom <- promoters(genes(TxDb.Hsapiens.UCSC.hg19.knownGene))
seqlevels(prom,force=T) <- seqlevels(prom)[!grepl("_", seqlevels(prom))]
bamfiles <- list.files(datdir,pattern='bam$',full=T)
labs <- rep(c('Broad','UW'),each=4)
cells <- rep(rep(c('GM12878','K562'),each=2),2)
meta <- data.frame(cellline=cells,lab=labs,file=bamfiles)
```

#### Generating Benchmarking Inputs

```{r count, results='hide', message=FALSE, warning=FALSE}
if(file.exists('h3k4me3.rda')){
    load('h3k4me3.rda')
}else{
    library(Rsubread)	
    anno <- data.frame(GeneID=seq_len(length(prom)),Chr=seqnames(prom), Start=start(prom),
                   End=end(prom), Strand=strand(prom))
    rc <- featureCounts(files=bamfiles,annot.ext=anno,allowMultiOverlap=TRUE,minOverlap=50,readExtension3=150,
                    ignoreDup=TRUE)$counts
    library(DESeq2)
    dds <- DESeqDataSetFromMatrix(countData=rc,colData=as.data.frame(meta),design= ~ lab + cellline)
    dds <- DESeq(dds,fitType="mean")
    dat <- as.data.frame(results(dds))
    colnames(dat) <- c('ind_covariate','effect_size','SE','stat','pval','padj')
    save(rc,prom,deseq,dat,file='h3k4me3.rda')
}
dim(dat)
head(dat)
dat <- dat[!is.na(dat[,2]),]
```
#### Check Covariate Diagnostics

```{r, chipseq-diag, fig.width=10, fig.height=3.5}
strat_hist(dat, pvalue="pval", covariate="ind_covariate", maxy=2)
rank_scatter(dat, pvalue="pval", covariate="ind_covariate")
```


#### Setup BenchDesign object 

```{r, chipseq-benchdesign}
bd <- initializeBenchDesign()
```

#### Run buildBench for the coverage covariate and examine results

Now, we're ready to construct the `SummarizedBenchmark` object, which will run
the functions specified in each method (these are actually sourced in from the
                                        helper scripts). 

```{r, chipseq-sb, results="hide", message=FALSE}
resN <- paste0(resdir, "/chipseq_summarizedBenchmark_",
               nrow(dat), ".RData")

duration <- NA
if (!file.exists(resN)){
  t1 <- proc.time()
  sb <- bd %>% buildBench(data=(dat %>% mutate(test_statistic = qnorm(exp(log(pval)-log(2)), lower.tail=FALSE) * sign(effect_size))), 
                          ftCols = c("ind_covariate"),
                          parallel=TRUE, BPPARAM=multicoreParam)
  save(sb, file=resN)
  duration <- round((proc.time()-t1)[3]/60,1)
}else{
  load(resN)
}
```


Next, we'll add the default performance metric for q-value assays. First, we have
to rename the assay to 'qvalue'.

```{r, chipseq-metrics}
# rename assay to qvalue
assayNames(sb) <- "qvalue"
sb <- addDefaultMetrics(sb)
```

Now, we'll plot the results.

```{r, chipseq-plot, results="hide", width=15, height=15}
# plot nrejects by method overall and stratified by covariate
rejections_scatter(sb,supplementary=FALSE)

rejection_scatter_bins(sb, covariate="ind_covariate", bins=4,
                       supplementary=FALSE)

# upset plot 
plotFDRMethodsOverlap(sb, 
                      alpha=0.05, nsets=ncol(sb),
                      order.by="freq", decreasing=TRUE,
                      supplementary=FALSE)

# properties of method-exclusive discoveries
methods <- c("ashs", "lfdr", "ihw-a10", "bl-df03", "qvalue", "bh", "bonf" )
plotCovariateBoxplots(sb, alpha=0.1, nsets=6, methods=methods, trans=log2, maxNum=5)
rm(bmi)
rm(bd)
rm(sb)

```

