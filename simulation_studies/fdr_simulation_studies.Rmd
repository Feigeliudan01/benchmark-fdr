---
title: "Benchmarking FDR Methods"
author: "Rafalab Journal Club Members"
date: "`r Sys.Date()`"
output: 
    html_document:
        toc: true
        toc_float: true
        highlight: tango
        number_sections: true
        code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

The goal of this working group is to benchmark recent covariate-adjusted FDR methods. For 
complete details, check out our [benchmark-fdr GitHub repo](https://github.com/pkimes/benchmark-fdr). 

In this R Markdown, we use a Monte Carlo simulation study  to evaluate different simulation scenarios: 

1. The `All nulls` simulation: All tests are simulated from the null distribution (no difference). 
2. add here... 
3. add here...
4. etc

In all cases, we define 

* $m$ = number of tests
* $M$ = Monte Carlo replications
* 

```{r}
m = 5000 # number of tests
M = 4 # number of MC reps

 # load helper functions
RPROJ <- list(PROJHOME = normalizePath(getwd()))
source(file.path(RPROJ$PROJHOME, "R/simulation-helpers.R"))
```


**Things to do**: add a summary of all the simulation studies we plan to do. 

## Methods to evaluate

- Bonferroni 
- BH
- IHW
- ASH
- BL
- Scott
- locfdr
- mixfdr



**Things to do**: add details, links, etc of methods here

## Metrics to evaluate

- Number of discoveries
- Control FDR at $\alpha$
- Power
- Relationship between $pi_0$ and covariate
- Assumptions: unimodal, etc

**Things to do**: Better describe metrics to evaluate our simulation studies



# The `All nulls` simulation

Simulate two standard normals with mean 0, sd = 1. Calculate t-statistic. 
Independent covariate: Uniform between 0, 1. Apply different methods. 

## Control for FDR and FWER at $\alpha$ 

In this section, we will plot the number of discoveries 
as a function of $\alpha$ (should be 0). We will also evaluate
methods control for false discovery rate (FDR) and family-wise 
error rate (FWER) at nominal $\alpha$ level ranging from [0.01, 0.1].

```{r, load-libraries, message=FALSE}
library(dplyr)
library(ggplot2)
library(doParallel)
```

Additional packages that you should install are: 
```{r, eval=FALSE}
library(genefilter)

library(IHW)
library(ashr)
library(qvalue)
library(swfdr)
library(fdrtool)
  ## to use IHWpaper::scott_fdrreg wrapper, need to install FDRreg v2.0 (only available github):   
  ## devtools::install_github(repo= 'jgscott/FDRreg', subdir='R_pkg/') 
library(FDRreg)
```

Simulate an example "null" dataset. `H` is an indicator representing the true null (0) or alternative status (1). `test_statistic` is the t-test statistic, `effect_size` is the difference in means, 
`pval` is the $p$-value from the t-test, `ind_covariate` (in this case) is the pooled standard deviation ($\sigma$), which reduces to the unpooled sd in this case, 
and `SE` is the standard error ($\frac{\sigma}{\sqrt{n}}$)
```{r example-simulate-null-data}
n_samples = 20
n_groups = 2

sim_df <- du_ttest_sim(m=m, pi0=1, effect_size=0, 
                       n_samples=n_samples, n_groups = 2)
head(sim_df)
```

Run following on odyssey and save output as RDS: 
```{r evaluate-methods-null-data, eval=FALSE}
library(dplyr)
library(ggplot2)
library(doParallel)

workingPath <- "/net/irizarryfs01/srv/export/irizarryfs01_backed_up/share_root/shicks/projects/benchmark-fdr"
source(file.path(workingPath, "simulation-helpers.R"))

# set these to a smaller number temporarily 
m = 5000 # number of tests
M = 500 # number of MC reps

n_samples = 20
n_groups = 2

alphas = seq(0.01, 0.1, length.out = 10)

nCores <- 10
registerDoParallel(cores = nCores)
workers <- getDoParWorkers()
backend <- getDoParName()
version <- getDoParVersion()

df.out <- foreach(i = 1:M, .verbose=T) %dopar% {
  sim_df <- du_ttest_sim(m=m, pi0=1, effect_size=0, n_samples=n_samples, n_groups=2)
  sim_runner(sim = sim_df, alphas = alphas)
}

df.out <- dplyr::bind_rows(df.out)

saveRDS(df.out, file=file.path(workingPath, "nullSims-Results.RDS"))
```

Load and plot results from RDS file: 
```{r, eval=FALSE}
# workingPath <- "/net/irizarryfs01/srv/export/irizarryfs01_backed_up/share_root/shicks/projects/benchmark-fdr"
# df.out <- readRDS(file=file.path(workingPath, "nullSims-Results.RDS"))
df.out <- readRDS(file=file.path(RPROJ$PROJHOME, "R/nullSims-Results.RDS"))

# Number of discoveries as a function of $\alpha$
df.out %>% dplyr::group_by(method, alpha) %>% 
      dplyr::filter(!(method %in% c("ash", "scott", "locfdr"))) %>%
      dplyr::summarize(n_rejects = mean(n_rejects), FDR = mean(FDP), 
                       FWER = mean(FWER), FPR = mean(FPR)) %>% 
    ggplot(aes(x = alpha, y = n_rejects, color = method)) + 
         geom_line() + geom_abline(linetype="dashed") + 
         xlab(expression(bold(paste("Nominal ",alpha)))) + ylab("Number of Discoveries") +
         theme(axis.title = element_text(face="bold") )

# False discovery rate as a function of $\alpha$
df.out %>% dplyr::group_by(method, alpha) %>%
        # dplyr::filter(!(method %in% c("ash", "scott", "locfdr"))) %>%
      dplyr::summarize(n_rejects = mean(n_rejects), FDR = mean(FDP), 
                       FWER = mean(FWER), FPR = mean(FPR)) %>% 
      ggplot(aes(x = alpha, y = FDR, color = method)) + 
         geom_line() + geom_abline(linetype="dashed") + 
         xlab(expression(bold(paste("Nominal ",alpha)))) + ylab("FDR") +
         theme(axis.title = element_text(face="bold") )

# Family wise error rate as a function of $\alpha$
df.out %>% dplyr::group_by(method, alpha) %>% 
         #  dplyr::filter(!(method %in% c("ash", "scott"))) %>%
      dplyr::summarize(n_rejects = mean(n_rejects), FDR = mean(FDP), 
                       FWER = mean(FWER), FPR = mean(FPR)) %>% 
      ggplot(aes(x = alpha, y = FWER, color = method)) + 
         geom_line() + geom_abline(linetype="dashed") + 
         xlab(expression(bold(paste("Nominal ",alpha)))) + ylab("FWER") +
         theme(axis.title = element_text(face="bold") )
```


## add here...  